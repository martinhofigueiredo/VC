{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assigment 2 Estimation of Apparent Motion\n",
    "\n",
    "<p style=\"text-align:left;\">\n",
    "    Jos√© Pedro Cruz\n",
    "    <span style=\"float:right;\">\n",
    "        up201504646\n",
    "    </span>\n",
    "</p>\n",
    "<p style=\"text-align:left;\">\n",
    "    Martinho Figueiredo\n",
    "    <span style=\"float:right;\">\n",
    "        up201506179\n",
    "    </span>\n",
    "</p>\n",
    "<p style=\"text-align:left;\">\n",
    "    Nuno Nascimento\n",
    "    <span style=\"float:right;\">\n",
    "        up201907933\n",
    "    </span>\n",
    "</p>\n",
    "\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/martinhofigueiredo/VC)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheme\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[Ingest Footage] -->|mp4 or mpegs| B{Multi Channel?}\n",
    "    B -->|Yes| C[Split into Channels]\n",
    "    B -->|No| D[Gray]-->H\n",
    "    C --> E[R]-->H\n",
    "    C --> F[G]-->H\n",
    "    C --> G[B]-->H\n",
    "    H{Multi Resolution?}-->|Yes|I[n Pyramid DownSampling Average]-->K\n",
    "    H-->|No|J[One Shot]-->K\n",
    "    K{algo} -->|HornShunck| M((.flo file))\n",
    "    K -->|LucasKanade| M\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    GT[Ground truth] --> B{BenchMark}\n",
    "    A(Flow Calculated) --> B\n",
    "    B --> AE(Angular Error and Std Dev)\n",
    "    B --> EE(Endpoint Error and Std Dev)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[import .flo file]-->C{Type}\n",
    "    C-->VF[Vector Field]\n",
    "    C-->MF[Middlebury Flow]\n",
    "    \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import struct\n",
    "import argparse\n",
    "import math\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4811.22s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Requirement already satisfied: wget in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# IMport dataset with public ground truth\n",
    "%pip install wget\n",
    "import os\n",
    "import subprocess\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "# Specify the URLs of the files to download\n",
    "url1 = \"https://vision.middlebury.edu/flow/data/comp/zip/other-gt-flow.zip\"\n",
    "url2 = \"https://vision.middlebury.edu/flow/data/comp/zip/other-color-allframes.zip\"\n",
    "url3 = \"https://vision.middlebury.edu/flow/data/comp/zip/eval-color-allframes.zip\"\n",
    "# Specify the destination folder to store the downloaded files\n",
    "destination_folder = \"dataset/\"\n",
    "\n",
    "# Download the files using wget\n",
    "file1 = wget.download(url1, out=destination_folder)\n",
    "file2 = wget.download(url2, out=destination_folder)\n",
    "file3 = wget.download(url3, out=destination_folder)\n",
    "\n",
    "# Unzip the files\n",
    "with zipfile.ZipFile(file1, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "with zipfile.ZipFile(file2, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "    \n",
    "with zipfile.ZipFile(file3, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "# Remove the zip files if needed\n",
    "os.remove(file1)\n",
    "os.remove(file2)\n",
    "os.remove(file3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all jpgs and pngs in a folder and returns a list of their respective path \n",
    "def get_frame_paths(folder_path):\n",
    "    frame_paths = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            frame_path = os.path.join(folder_path, filename)\n",
    "            frame_paths.append(frame_path)\n",
    "    frame_paths.sort()\n",
    "    print(frame_paths)\n",
    "    return frame_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "Ingest"
    ]
   },
   "outputs": [],
   "source": [
    "# Checks if the inut file is a directory and if it is it will try and get the frames inside the folder\n",
    "# it will check if it is and mp4 and if it is it will read it and create a list of frames\n",
    "def get_input_frames(input_path):\n",
    "    frames = []\n",
    "    if os.path.isdir(input_path):\n",
    "        frame_paths = get_frame_paths(input_path)\n",
    "        print(f\"{frame_paths}\")\n",
    "        frames = [cv2.imread(frame_path) for frame_path in frame_paths]\n",
    "    else :\n",
    "        if input_path.endswith('.mp4'):\n",
    "            cap = cv2.VideoCapture(total_path)\n",
    "            frames = []\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "    return frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Algo Config from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads a yaml file with the parameters to run the code\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        config['input_path']= os.getcwd()+config['input_path'] # Fix to run in the location it called\n",
    "        print(config)\n",
    "    return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flo file format Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "Flow"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Angular Error: 1.5791076\n",
      "Standard Deviation of Angular Error: 0.5013132\n",
      "Mean Endpoint Error: 1.5791076\n",
      "Standard Deviation of Endpoint Error: 0.5013132\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "def write_flow_field(flow, filename):\n",
    "    height, width, _ = flow.shape\n",
    "    with open(filename, 'wb') as f:\n",
    "        # Write the magic number: 'PIEH' in ASCII\n",
    "        f.write(b'PIEH')\n",
    "\n",
    "        # Write the width and height of the flow field\n",
    "        f.write(np.array(width).astype(np.int32).tobytes())\n",
    "        f.write(np.array(height).astype(np.int32).tobytes())\n",
    "\n",
    "        # Interleave the u and v values and write the flow field data\n",
    "        flow_data = np.concatenate((flow[..., 0], flow[..., 1]), axis=1)\n",
    "        f.write(flow_data.astype(np.float32).tobytes())\n",
    "\n",
    "def read_flow_field(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the magic number\n",
    "        magic = f.read(4).decode()\n",
    "        if magic != 'PIEH':\n",
    "            raise ValueError('Invalid flow file format.')\n",
    "\n",
    "        # Read the width and height of the flow field\n",
    "        width = np.frombuffer(f.read(4), dtype=np.int32)[0]\n",
    "        height = np.frombuffer(f.read(4), dtype=np.int32)[0]\n",
    "\n",
    "        # Read the flow field data\n",
    "        flow_data = np.frombuffer(f.read(), dtype=np.float32)\n",
    "        flow = flow_data.reshape((height, width, 2))\n",
    "\n",
    "    return flow\n",
    "\n",
    "\n",
    "def calculate_angular_error(flow_gt, flow_pred):\n",
    "    flow_gt_norm = np.sqrt(np.sum(flow_gt ** 2, axis=2))\n",
    "    flow_pred_norm = np.sqrt(np.sum(flow_pred ** 2, axis=2))\n",
    "    dot_product = np.sum(flow_gt * flow_pred, axis=2)\n",
    "    cos_theta = np.clip(dot_product / (flow_gt_norm * flow_pred_norm), -1.0, 1.0)\n",
    "    angular_error = np.arccos(cos_theta)\n",
    "    return angular_error\n",
    "\n",
    "def calculate_endpoint_error(flow_gt, flow_pred):\n",
    "    endpoint_error = np.sqrt(np.sum((flow_gt - flow_pred) ** 2, axis=2))\n",
    "    return endpoint_error\n",
    "\n",
    "\n",
    "def calculate_error_statistics(error):\n",
    "    mean_error = np.mean(angular_error)\n",
    "    std_error = np.std(angular_error)\n",
    "    return mean_error, std_error\n",
    "\n",
    "# Example usage\n",
    "flow_gt = read_flow_field('/workspace/VC/assignment2/dataset/other-gt-flow/Urban2/flow10.flo')\n",
    "write_flow_field(flow_gt, \"flow_gt.flo\")\n",
    "flow_pred = read_flow_field('flow_gt.flo')\n",
    "\n",
    "angular_error = calculate_angular_error(flow_gt, flow_pred)\n",
    "angular_mean, angular_std = calculate_error_statistics(angular_error)\n",
    "\n",
    "print('Mean Angular Error:', angular_mean)\n",
    "print('Standard Deviation of Angular Error:', angular_std)\n",
    "\n",
    "endpoint_error = calculate_endpoint_error(flow_gt, flow_pred)\n",
    "endpoint_mean, endpoint_std = calculate_error_statistics(endpoint_error)\n",
    "\n",
    "print('Mean Endpoint Error:', endpoint_mean)\n",
    "print('Standard Deviation of Endpoint Error:', endpoint_std)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading File \\'config_LK.yml\\'\")\n",
    "\n",
    "config = load_config('config_LK.yml')\n",
    "\n",
    "input_path = config['input_path']\n",
    "\n",
    "frames = get_input_frames(input_path)\n",
    "\n",
    "\n",
    "feature_params = dict(\n",
    "    maxCorners=config['max_corners'],\n",
    "    qualityLevel=config['quality_level'],\n",
    "    minDistance=config['min_distance'],\n",
    "    blockSize=config['block_size']\n",
    ")\n",
    "lk_params = dict(\n",
    "    winSize=(config['window_size'], config['window_size']),\n",
    "    maxLevel=config['max_level'],\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, config['max_iterations'], config['epsilon'])\n",
    ")\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "old_frame = frames[0]\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "mask = np.zeros_like(old_frame)\n",
    "height, width, channels = old_frame.shape\n",
    "mask_flow = np.zeros((height,width,2))\n",
    "print(\"DIM: \", mask_flow.shape)\n",
    "\n",
    "for frame_num in frames[1:]:\n",
    "    \n",
    "    current_frame = frame_num\n",
    "    frame_gray = cv2.cvtColor(frame_num, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    print(\"p1: \", np.asarray(p1).shape)\n",
    "    print(np.asarray(p1).shape)\n",
    "    print(p1)\n",
    "    if p1 is not None:\n",
    "        \n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "    \n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "        \n",
    "    frame_with_flow = cv2.add(current_frame, mask)\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "\n",
    "print(\"mask: \",mask.shape)\n",
    "cv2.imwrite('flow.png', frame_with_flow)\n",
    "write_flow_field(mask,'flow_field.flo')\n",
    "\n",
    "\n",
    "flow_data = read_flow_field('/Users/nmcna/Desktop/FEUP/4oano/2osemestre/VC/assignment2/dataset/other-gt-flow/Urban2/flow10.flo')  # Read the .flo file\n",
    "\n",
    "# Compute the magnitude and angle of the flow vectors\n",
    "magnitude, angle = cv2.cartToPolar(flow_data[..., 0], flow_data[..., 1])\n",
    "\n",
    "# Visualize the flow field\n",
    "hue = angle * 180 / np.pi / 2\n",
    "saturation = np.ones_like(magnitude)\n",
    "value = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "flow_visualization = cv2.cvtColor(cv2.merge((hue, saturation, value)).astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "#teste = cv2.merge((hue, saturation, value)).astype(np.uint8)\n",
    "# Display the flow visualization\n",
    "cv2.imshow('Optical Flow', flow_visualization)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('dataset/other-data/Urban2/frame07.png')\n",
    "\n",
    "flow = read_flow_field('dataset/other-gt-flow/Urban2/flow10.flo')\n",
    "\n",
    "warped = cv2.remap(image, flow, None, cv2.INTER_LINEAR)\n",
    "\n",
    "cv2.imshow('warp', warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horn-Shunchk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Image\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "\n",
    "def display_image(image):\n",
    "    # Convert the OpenCV image to a PIL image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = PIL.Image.fromarray(image)\n",
    "    \n",
    "    # Display the image using the Jupyter inline magic\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    display(Image(data=buffered.getvalue()))\n",
    "\n",
    "\n",
    "# Load the tuning parameters from the config file\n",
    "with open('config_HS.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Load the input frames\n",
    "input_path = os.getcwd()+config['input_path']\n",
    "input_frames = get_input_frames(input_path)\n",
    "\n",
    "# Initialize the flow field for the first frame with zeros\n",
    "prev_frame = input_frames[0]\n",
    "flow = np.zeros((prev_frame.shape[0], prev_frame.shape[1], 2), dtype=np.float32)\n",
    "\n",
    "# Set the Horn-Schunck parameters\n",
    "alpha = config['alpha']\n",
    "num_iterations = config['num_iterations']\n",
    "epsilon = config['epsilon']\n",
    "\n",
    "# Define the Gaussian pyramid levels\n",
    "num_levels = config['num_levels']\n",
    "pyramid_scale = config['pyramid_scale']\n",
    "\n",
    "# Create an output widget for displaying images\n",
    "output_widget = Image()\n",
    "\n",
    "# Compute the optical flow for each level of the pyramid\n",
    "for level in range(num_levels):\n",
    "    # Downsample the input frames and flow field\n",
    "    curr_frame = cv2.resize(prev_frame, None, fx=pyramid_scale, fy=pyramid_scale)\n",
    "    curr_flow = cv2.resize(flow, None, fx=pyramid_scale, fy=pyramid_scale)\n",
    "\n",
    "    # Compute the optical flow using the multi-channel Horn-Schunck algorithm\n",
    "    for i in range(num_iterations):\n",
    "        # Split the flow field into x and y components\n",
    "        fx, fy = np.split(curr_flow, 2, axis=2)\n",
    "\n",
    "        # Compute the Laplacian of the flow field\n",
    "        fxx, _ = np.gradient(fx)\n",
    "        _, fyy = np.gradient(fy)\n",
    "        fxy = np.gradient(fx, axis=0)[0] + np.gradient(fy, axis=1)[1]\n",
    "\n",
    "        # Compute the temporal derivative of the flow field\n",
    "        ft = next_frame_gray - prev_frame_gray + np.sum(curr_flow * np.dstack((fx, fy)), axis=2)\n",
    "\n",
    "        # Compute the update to the flow field\n",
    "        numerator = fxx * fy ** 2 - 2 * fx * fy * fxy + fyy * fx ** 2 - ft * fx * fy\n",
    "        denominator = fx ** 2 + fy ** 2 + alpha\n",
    "        update = numerator / (denominator[..., np.newaxis] + epsilon)\n",
    "\n",
    "        # Update the flow field\n",
    "        curr_flow += update\n",
    "\n",
    "        # Visualize the current flow field\n",
    "        if display:\n",
    "            flow_image = flow_to_color(curr_flow)\n",
    "            display_image(flow_image)\n",
    "\n",
    "    # Convert the flow field to polar coordinates\n",
    "    magnitude, angle = cv2.cartToPolar(curr_flow[..., 0], curr_flow[..., 1], angleInDegrees=True)\n",
    "\n",
    "    #return curr_flow, magnitude, angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done Using [flowvid](https://github.com/diegoroyo/flowvid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "File flow_gt.flo has wrong tag (1212500352.0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m flo_frame \u001b[39m=\u001b[39m fv\u001b[39m.\u001b[39mnormalize_frame(flo_data)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Normalize all flo files at once, applying a clamp/gamma curve\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m flo_video \u001b[39m=\u001b[39m fv\u001b[39m.\u001b[39;49mnormalize_video(flo_data, clamp_pct\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m, gamma\u001b[39m=\u001b[39;49m\u001b[39m1.5\u001b[39;49m)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Conversion from flow data to RGB\u001b[39;00m\n\u001b[1;32m     16\u001b[0m rgb_frames \u001b[39m=\u001b[39m fv\u001b[39m.\u001b[39mflow_to_rgb(flo_video)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/flowvid/core/__init__.py:61\u001b[0m, in \u001b[0;36mnormalize_video\u001b[0;34m(data, clamp_pct, gamma, verbose)\u001b[0m\n\u001b[1;32m     59\u001b[0m data\u001b[39m.\u001b[39massert_type(\u001b[39m'\u001b[39m\u001b[39mflo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mepe\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mget_type() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mflo\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39m_add_filter(NormalizeFlowVideo(data, clamp_pct, gamma, verbose))\n\u001b[1;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39m_add_filter(NormalizeEPEVideo(data, clamp_pct, gamma, verbose))\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/flowvid/core/filters/normalize_flow.py:52\u001b[0m, in \u001b[0;36mNormalizeFlowVideo.__init__\u001b[0;34m(self, flow_data, clamp_pct, gamma, verbose)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inv_gamma \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m gamma\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose \u001b[39m=\u001b[39m verbose\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_max_flow()\n\u001b[1;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clamp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max \u001b[39m*\u001b[39m clamp_pct\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/flowvid/core/filters/normalize_flow.py:63\u001b[0m, in \u001b[0;36mNormalizeFlowVideo._find_max_flow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose:\n\u001b[1;32m     62\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mApplying normalization to the whole video...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[39mfor\u001b[39;00m flow \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flow_data:\n\u001b[1;32m     64\u001b[0m     fu \u001b[39m=\u001b[39m flow[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m     65\u001b[0m     fv \u001b[39m=\u001b[39m flow[:, :, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/flowvid/core/filterable.py:23\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_filters(item) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items())\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/flowvid/input/flo_data.py:12\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_items\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m (FloData\u001b[39m.\u001b[39;49m_read_flow(filename) \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/flowvid/input/flo_data.py:35\u001b[0m, in \u001b[0;36mFloData._read_flow\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m tag \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(file\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32, count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tag \u001b[39m==\u001b[39m FloData\u001b[39m.\u001b[39mTAG_FLOAT:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m     36\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{f}\u001b[39;00m\u001b[39m has wrong tag (\u001b[39m\u001b[39m{t}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(f\u001b[39m=\u001b[39mfile_path, t\u001b[39m=\u001b[39mtag))\n\u001b[1;32m     38\u001b[0m [width, height] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(\n\u001b[1;32m     39\u001b[0m     file\u001b[39m.\u001b[39mread(\u001b[39m8\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32, count\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     41\u001b[0m dimensions \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m  \u001b[39m# u (horizontal) and v (vertical)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: File flow_gt.flo has wrong tag (1212500352.0)"
     ]
    }
   ],
   "source": [
    "import flowvid\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "\n",
    "import flowvid as fv\n",
    "\n",
    "flo_data = fv.input.flo('flow_gt.flo')\n",
    "\n",
    "# You can normalize by frame OR the whole video\n",
    "# Normalize each flo file independently\n",
    "flo_frame = fv.normalize_frame(flo_data)\n",
    "# Normalize all flo files at once, applying a clamp/gamma curve\n",
    "flo_video = fv.normalize_video(flo_data, clamp_pct=0.8, gamma=1.5)\n",
    "\n",
    "# Conversion from flow data to RGB\n",
    "rgb_frames = fv.flow_to_rgb(flo_video)\n",
    "\n",
    "out5 = fv.output.show_plot(title='Flow colors', framerate=10)\n",
    "out5.show_all(rgb_frames, show_count=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# IMport dataset with public ground truth\n",
    "%pip install wget\n",
    "import os\n",
    "import subprocess\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "# Specify the URLs of the files to download\n",
    "url1 = \"https://vision.middlebury.edu/flow/data/comp/zip/other-gt-flow.zip\"\n",
    "url2 = \"https://vision.middlebury.edu/flow/data/comp/zip/other-color-allframes.zip\"\n",
    "url3 = \"https://vision.middlebury.edu/flow/data/comp/zip/eval-color-allframes.zip\"\n",
    "# Specify the destination folder to store the downloaded files\n",
    "destination_folder = \"dataset/\"\n",
    "\n",
    "# Download the files using wget\n",
    "file1 = wget.download(url1, out=destination_folder)\n",
    "file2 = wget.download(url2, out=destination_folder)\n",
    "file3 = wget.download(url3, out=destination_folder)\n",
    "\n",
    "# Unzip the files\n",
    "with zipfile.ZipFile(file1, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "with zipfile.ZipFile(file2, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "    \n",
    "with zipfile.ZipFile(file3, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "# Remove the zip files if needed\n",
    "os.remove(file1)\n",
    "os.remove(file2)\n",
    "os.remove(file3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bench Marking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_results():\n",
    "    # Create an empty dataframe to store the results\n",
    "    results_df = pd.DataFrame(columns=['DataSet', 'Average Angular Error '])\n",
    "    \n",
    "    # Iterate through the function calls and store the results\n",
    "    for fc in fcalls:\n",
    "        # Call the function\n",
    "        result = fc()\n",
    "        \n",
    "        # Add the function name and result to the dataframe\n",
    "        results_df = results_df.append({'Function': fc.__name__, 'Result': result}, ignore_index=True)\n",
    "    \n",
    "    # Display the results as a markdown table\n",
    "    display(results_df.to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
