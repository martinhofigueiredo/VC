{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assigment 2 Estimation of Apparent Motion\n",
    "\n",
    "<p style=\"text-align:left;\">\n",
    "    Jos√© Pedro Cruz\n",
    "    <span style=\"float:right;\">\n",
    "        up201504646\n",
    "    </span>\n",
    "</p>\n",
    "<p style=\"text-align:left;\">\n",
    "    Martinho Figueiredo\n",
    "    <span style=\"float:right;\">\n",
    "        up201506179\n",
    "    </span>\n",
    "</p>\n",
    "<p style=\"text-align:left;\">\n",
    "    Nuno Nascimento\n",
    "    <span style=\"float:right;\">\n",
    "        up201907933\n",
    "    </span>\n",
    "</p>\n",
    "\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/martinhofigueiredo/VC)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheme\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[Ingest Footage] -->|mp4 or mpegs| B{Multi Channel?}\n",
    "    B -->|Yes| C[Split into Channels]\n",
    "    B -->|No| D[Gray]-->H\n",
    "    C --> E[R]-->H\n",
    "    C --> F[G]-->H\n",
    "    C --> G[B]-->H\n",
    "    H{Multi Resolution?}-->|Yes|I[n Pyramid DownSampling Average]-->K\n",
    "    H-->|No|J[One Shot]-->K\n",
    "    K{algo} -->|HornShunck| M((FLOW))\n",
    "    K -->|LucasKanade| M\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import struct\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads a yaml file with the parameters to run the code\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all jpgs and pngs in a folder and returns a list of their respective path \n",
    "def get_frame_paths(folder_path):\n",
    "    frame_paths = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            frame_path = os.path.join(folder_path, filename)\n",
    "            frame_paths.append(frame_path)\n",
    "    frame_paths.sort()\n",
    "    return frame_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the inut file is a directory and if it is it will try and get the frames inside the folder\n",
    "# it will check if it is and mp4 and if it is it will read it and create a list of frames\n",
    "def get_input_frames(input_path):\n",
    "    frames = []\n",
    "    if os.path.isdir(input_path):\n",
    "        frame_paths = get_frame_paths(input_path)\n",
    "        print(f\"{frame_paths}\")\n",
    "        frames = [cv2.imread(frame_path) for frame_path in frame_paths]\n",
    "    else :\n",
    "        if input_path.endswith('.mp4'):\n",
    "            cap = cv2.VideoCapture(input_path)\n",
    "            frames = []\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_flow(filename, flow):\n",
    "    height, width = flow.shape[:2]\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(struct.pack('f', width))\n",
    "        f.write(struct.pack('f', height))\n",
    "        f.write(flow.astype(np.float32).tobytes())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_flow(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        width = struct.unpack('f', f.read(4))[0]\n",
    "        height = struct.unpack('f', f.read(4))[0]\n",
    "        flow_bytes = f.read()\n",
    "\n",
    "    flow = np.frombuffer(flow_bytes, np.float32)\n",
    "    flow = flow.reshape(int(height), int(width), 2)\n",
    "\n",
    "    return flow\n",
    "\n",
    "def compute_angular_error(flow_gt, flow_est):\n",
    "    angles_gt = np.arctan2(flow_gt[:, :, 1], flow_gt[:, :, 0])\n",
    "    angles_est = np.arctan2(flow_est[:, :, 1], flow_est[:, :, 0])\n",
    "    error = (np.sum((angles_gt - angles_est) ** 2, axis=2))\n",
    "    return np.mean(error)\n",
    "\n",
    "def compute_endpoint_error(flow_gt, flow_est):\n",
    "    error = np.sqrt(np.sum((flow_gt - flow_est) ** 2, axis=2))\n",
    "    return np.mean(error)\n",
    "\n",
    "def compare_flow_files(file_gt, file_est):\n",
    "    flow_gt = read_flow(file_gt)\n",
    "    flow_est = read_flow(file_est)\n",
    "\n",
    "    error_endpoint = compute_endpoint_error(flow_gt, flow_est)\n",
    "    error_angular = compute_angular_error(flow_gt, flow_est)\n",
    "\n",
    "    return error_endpoint, error_angular"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading File 'config_LK.yml'\n",
      "c:\\Users\\nmcna\\Desktop\\FEUP\\4oano\\2osemestre\\VC\\assignment2\\dataset\\eval-data\\Army\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 23\u001b[0m\n\u001b[0;32m     11\u001b[0m feature_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m     12\u001b[0m     maxCorners\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mmax_corners\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     13\u001b[0m     qualityLevel\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mquality_level\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     14\u001b[0m     minDistance\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mmin_distance\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     15\u001b[0m     blockSize\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mblock_size\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m lk_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m     18\u001b[0m     winSize\u001b[39m=\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mwindow_size\u001b[39m\u001b[39m'\u001b[39m], config[\u001b[39m'\u001b[39m\u001b[39mwindow_size\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m     19\u001b[0m     maxLevel\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mmax_level\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     20\u001b[0m     criteria\u001b[39m=\u001b[39m(cv2\u001b[39m.\u001b[39mTERM_CRITERIA_EPS \u001b[39m|\u001b[39m cv2\u001b[39m.\u001b[39mTERM_CRITERIA_COUNT, config[\u001b[39m'\u001b[39m\u001b[39mmax_iterations\u001b[39m\u001b[39m'\u001b[39m], config[\u001b[39m'\u001b[39m\u001b[39mepsilon\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m prev_frame \u001b[39m=\u001b[39m frames[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     24\u001b[0m prev_gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(prev_frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     25\u001b[0m prev_corners \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mgoodFeaturesToTrack(prev_gray, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfeature_params)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(f\"Loading File \\'config_LK.yml\\'\")\n",
    "\n",
    "config = load_config('config_LK.yml')\n",
    "\n",
    "input_path = os.getcwd()+config['input_path']\n",
    "\n",
    "print(input_path)\n",
    "frames = get_input_frames(input_path)\n",
    "\n",
    "\n",
    "feature_params = dict(\n",
    "    maxCorners=config['max_corners'],\n",
    "    qualityLevel=config['quality_level'],\n",
    "    minDistance=config['min_distance'],\n",
    "    blockSize=config['block_size']\n",
    ")\n",
    "lk_params = dict(\n",
    "    winSize=(config['window_size'], config['window_size']),\n",
    "    maxLevel=config['max_level'],\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, config['max_iterations'], config['epsilon'])\n",
    ")\n",
    "\n",
    "prev_frame = frames[0]\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
    "prev_roi = cv2.boundingRect(prev_corners)\n",
    "\n",
    "flow_list = []  #List to store optical flow vectors\n",
    "\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for curr_frame in frames[1:]:\n",
    "    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    curr_corners, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_corners, None, **lk_params)\n",
    "\n",
    "    good_prev_corners = prev_corners[status == 1]\n",
    "    good_curr_corners = curr_corners[status == 1]\n",
    "\n",
    "    flow = good_curr_corners - good_prev_corners # Calculate optical flow vectores\n",
    "    \n",
    "    flow_list.append(flow)\n",
    "\n",
    "    M, _ = cv2.findHomography(good_prev_corners, good_curr_corners, cv2.RANSAC, config['ransac_threshold'])\n",
    "\n",
    "    warped_roi = cv2.warpPerspective(prev_frame, M, (curr_frame.shape[1], curr_frame.shape[0]))\n",
    "    warped_mask = cv2.warpPerspective(mask, M, (curr_frame.shape[1], curr_frame.shape[0]))\n",
    "\n",
    "    output = curr_frame.copy()\n",
    "    output[warped_mask != 0] = 0\n",
    "    output = cv2.add(output, warped_roi)\n",
    "\n",
    "    ax.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "\n",
    "    prev_gray = curr_gray.copy()\n",
    "    prev_corners = good_curr_corners.reshape(-1, 1, 2)\n",
    "    prev_roi = cv2.boundingRect(prev_corners)\n",
    "flow_array = np.array(flow_list)\n",
    "\n",
    "output_file = 'Optical_flow.flo'\n",
    "write_flow(output_file,flow_array)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horn-Shunchk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Image\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "\n",
    "def display_image(image):\n",
    "    # Convert the OpenCV image to a PIL image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = PIL.Image.fromarray(image)\n",
    "    \n",
    "    # Display the image using the Jupyter inline magic\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    display(Image(data=buffered.getvalue()))\n",
    "\n",
    "def flow_to_color(flow, max_flow=None):\n",
    "    \"\"\"\n",
    "    Convert optical flow to RGB image using the Middlebury color code.\n",
    "    \"\"\"\n",
    "    assert flow.ndim == 3 and flow.shape[2] == 2, \"input flow must have shape (H, W, 2)\"\n",
    "    if max_flow is None:\n",
    "        max_flow = np.max(np.abs(flow))\n",
    "    \n",
    "    eps = 1e-5\n",
    "    unknown_mask = np.logical_or(np.isnan(flow[..., 0]), np.isnan(flow[..., 1]))\n",
    "    flow = flow / (max_flow + eps)\n",
    "    flow[..., 0] = 0.5 + flow[..., 0] / 2\n",
    "    flow[..., 1] = 0.5 - flow[..., 1] / 2\n",
    "    flow[..., 1] *= -1\n",
    "    flow[unknown_mask, :] = 0\n",
    "    \n",
    "    return (255 * flow).astype(np.uint8)\n",
    "\n",
    "# Load the tuning parameters from the config file\n",
    "with open('config_HS.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Load the input frames\n",
    "input_path = os.getcwd()+config['input_path']\n",
    "input_frames = get_input_frames(input_path)\n",
    "\n",
    "# Initialize the flow field for the first frame with zeros\n",
    "prev_frame = input_frames[0]\n",
    "flow = np.zeros((prev_frame.shape[0], prev_frame.shape[1], 2), dtype=np.float32)\n",
    "\n",
    "# Set the Horn-Schunck parameters\n",
    "alpha = config['alpha']\n",
    "num_iterations = config['num_iterations']\n",
    "epsilon = config['epsilon']\n",
    "\n",
    "# Define the Gaussian pyramid levels\n",
    "num_levels = config['num_levels']\n",
    "pyramid_scale = config['pyramid_scale']\n",
    "\n",
    "# Create an output widget for displaying images\n",
    "output_widget = Image()\n",
    "\n",
    "# Compute the optical flow for each level of the pyramid\n",
    "for level in range(num_levels):\n",
    "    # Downsample the input frames and flow field\n",
    "    curr_frame = cv2.resize(prev_frame, None, fx=pyramid_scale, fy=pyramid_scale)\n",
    "    curr_flow = cv2.resize(flow, None, fx=pyramid_scale, fy=pyramid_scale)\n",
    "\n",
    "    # Compute the optical flow using the multi-channel Horn-Schunck algorithm\n",
    "    for i in range(num_iterations):\n",
    "        # Split the flow field into x and y components\n",
    "        fx, fy = np.split(curr_flow, 2, axis=2)\n",
    "\n",
    "        # Compute the Laplacian of the flow field\n",
    "        fxx, _ = np.gradient(fx)\n",
    "        _, fyy = np.gradient(fy)\n",
    "        fxy = np.gradient(fx, axis=0)[0] + np.gradient(fy, axis=1)[1]\n",
    "\n",
    "        # Compute the temporal derivative of the flow field\n",
    "        ft = next_frame_gray - prev_frame_gray + np.sum(curr_flow * np.dstack((fx, fy)), axis=2)\n",
    "\n",
    "        # Compute the update to the flow field\n",
    "        numerator = fxx * fy ** 2 - 2 * fx * fy * fxy + fyy * fx ** 2 - ft * fx * fy\n",
    "        denominator = fx ** 2 + fy ** 2 + alpha\n",
    "        update = numerator / (denominator[..., np.newaxis] + epsilon)\n",
    "\n",
    "        # Update the flow field\n",
    "        curr_flow += update\n",
    "\n",
    "        # Visualize the current flow field\n",
    "        if display:\n",
    "            flow_image = flow_to_color(curr_flow)\n",
    "            display_image(flow_image)\n",
    "\n",
    "    # Convert the flow field to polar coordinates\n",
    "    magnitude, angle = cv2.cartToPolar(curr_flow[..., 0], curr_flow[..., 1], angleInDegrees=True)\n",
    "\n",
    "    #return curr_flow, magnitude, angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bench Marking\n",
    "\n",
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMport dataset with public ground truth\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "# Specify the URLs of the files to download\n",
    "url1 = \"https://vision.middlebury.edu/flow/data/comp/zip/other-gt-flow.zip\"\n",
    "url2 = \"https://vision.middlebury.edu/flow/data/comp/zip/other-color-allframes.zip\"\n",
    "url3 = \"https://vision.middlebury.edu/flow/data/comp/zip/eval-color-allframes.zip\"\n",
    "# Specify the destination folder to store the downloaded files\n",
    "destination_folder = \"dataset/\"\n",
    "\n",
    "# Download the files using wget\n",
    "file1 = wget.download(url1, out=destination_folder)\n",
    "file2 = wget.download(url2, out=destination_folder)\n",
    "file3 = wget.download(url3, out=destination_folder)\n",
    "\n",
    "# Unzip the files\n",
    "with zipfile.ZipFile(file1, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "with zipfile.ZipFile(file2, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "    \n",
    "with zipfile.ZipFile(file3, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "# Remove the zip files if needed\n",
    "os.remove(file1)\n",
    "os.remove(file2)\n",
    "os.remove(file3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
